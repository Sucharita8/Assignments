{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "039138e8",
   "metadata": {},
   "source": [
    "# Ebeddings challenge\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1626b476",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating synthetic datasets...\n",
      "Loading sentence embedding model...\n",
      "Generating recommendations...\n",
      "\n",
      "Sample output:\n",
      "User u000 → Recommended Books: ['b084', 'b055', 'b049']\n",
      "User u001 → Recommended Books: ['b090', 'b040', 'b086']\n",
      "User u002 → Recommended Books: ['b070', 'b075', 'b061']\n",
      "User u003 → Recommended Books: ['b013', 'b096', 'b048']\n",
      "User u004 → Recommended Books: ['b089', 'b018', 'b012']\n"
     ]
    }
   ],
   "source": [
    "# Book Recommender - Student Version\n",
    "# Final Project — Embeddings and Semantic Understanding\n",
    "\n",
    "from faker import Faker\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "# Optional: from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# === NOTES FOR ALL PLATFORMS ===\n",
    "# - If you are on Windows, make sure you install dependencies with:\n",
    "#     pip install pandas faker sentence-transformers scikit-learn\n",
    "#\n",
    "# - If you're on Mac and using Apple Silicon (M1/M2/M3), you may face issues\n",
    "#   if your model runs on 'mps' (Metal Performance Shaders).\n",
    "#   This can break compatibility with sklearn. If that happens, use .cpu().numpy()\n",
    "#   or just force the model to run on CPU by:\n",
    "#       import torch; torch.device(\"cpu\")\n",
    "#   and avoid `.to(\"mps\")` or `.to(\"cuda\")`.\n",
    "\n",
    "# ---------------------\n",
    "# STEP 1. Generate Users\n",
    "# ---------------------\n",
    "\n",
    "def generate_users(num_users=50):\n",
    "    faker = Faker()\n",
    "    random.seed(42)\n",
    "    users = []\n",
    "    for i in range(num_users):\n",
    "        user_id = f\"u{i:03d}\"\n",
    "        profile = faker.job() + \" who enjoys \" + faker.word()\n",
    "        reviews = [faker.sentence(nb_words=10) for _ in range(random.randint(2, 4))]\n",
    "        ratings = [random.randint(1, 5) for _ in range(len(reviews))]\n",
    "        users.append({\n",
    "            \"user_id\": user_id,\n",
    "            \"profile\": profile,\n",
    "            \"reviews\": reviews,\n",
    "            \"ratings\": ratings\n",
    "        })\n",
    "    return pd.DataFrame(users)\n",
    "\n",
    "# ---------------------\n",
    "# STEP 2. Generate Books\n",
    "# ---------------------\n",
    "\n",
    "def generate_books(num_books=100):\n",
    "    faker = Faker()\n",
    "    books = []\n",
    "    for i in range(num_books):\n",
    "        book_id = f\"b{i:03d}\"\n",
    "        title = faker.sentence(nb_words=4).rstrip('.')\n",
    "        description = faker.paragraph(nb_sentences=3)\n",
    "        books.append({\n",
    "            \"book_id\": book_id,\n",
    "            \"title\": title,\n",
    "            \"description\": description\n",
    "        })\n",
    "    return pd.DataFrame(books)\n",
    "\n",
    "# ---------------------\n",
    "# STEP 3. Save Data to CSV (Optional for viewing)\n",
    "# ---------------------\n",
    "\n",
    "def save_datasets(users, books):\n",
    "    users.to_csv(\"users.csv\", index=False)\n",
    "    books.to_csv(\"books.csv\", index=False)\n",
    "\n",
    "# ---------------------\n",
    "# STEP 4. Recommender Logic (TO COMPLETE)\n",
    "# ---------------------\n",
    "\n",
    "def recommend_books(user_df, book_df, model, top_k=3):\n",
    "    recommendations = {}\n",
    "\n",
    "    # Prepare book input text: title + description\n",
    "    book_texts = (book_df[\"title\"] + \" \" + book_df[\"description\"]).tolist()\n",
    "\n",
    "    # === WARNING: This returns Torch tensors — not NumPy ===\n",
    "    book_embeddings = model.encode(book_texts, convert_to_tensor=True).cpu().numpy()\n",
    "    # Optional: convert to numpy if needed\n",
    "    # book_embeddings = book_embeddings.cpu().numpy()\n",
    "\n",
    "    for idx, user in user_df.iterrows():\n",
    "        # Combine user's profile and reviews\n",
    "        user_text = user[\"profile\"] + \" \" + \" \".join(user[\"reviews\"])\n",
    "\n",
    "        # === EMBEDDING FOR USER INPUT ===\n",
    "        user_embedding = model.encode([user_text], convert_to_tensor=True).cpu().numpy()\n",
    "        \n",
    "        \n",
    "        # Compute cosine similarity between user and all books\n",
    "        similarities = cosine_similarity(user_embedding, book_embeddings)[0]\n",
    "        \n",
    "        top_indices = np.argsort(similarities)[::-1][:top_k]\n",
    "        \n",
    "        # Get top_k recommended book_ids\n",
    "        top_books = [book_df.iloc[i][\"book_id\"] for i in top_indices]\n",
    "        \n",
    "        recommendations[user[\"user_id\"]] = top_books\n",
    "\n",
    "        # === YOUR TASK STARTS HERE ===\n",
    "\n",
    "    return recommendations\n",
    "\n",
    "# ---------------------\n",
    "# STEP 5. Main Run\n",
    "# ---------------------\n",
    "\n",
    "def main():\n",
    "    print(\"Generating synthetic datasets...\")\n",
    "    users = generate_users()\n",
    "    books = generate_books()\n",
    "    save_datasets(users, books)\n",
    "\n",
    "    print(\"Loading sentence embedding model...\")\n",
    "    model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "    print(\"Generating recommendations...\\n\")\n",
    "    recommendations = recommend_books(users, books, model)\n",
    "\n",
    "    print(\"Sample output:\")\n",
    "    for user_id, book_ids in list(recommendations.items())[:5]:\n",
    "        print(f\"User {user_id} → Recommended Books: {book_ids}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d3ddaa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
